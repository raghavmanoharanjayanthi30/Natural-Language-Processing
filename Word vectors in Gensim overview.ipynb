{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e52cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word embedding in another python library called Gensim\n",
    "\n",
    "#previously,looked at text classification using spacy word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f9dc53d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: pyfume in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Requirement already satisfied: simpful in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.11.0)\n",
      "Requirement already satisfied: fst-pso in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in /Users/raghavraahul/anaconda3/lib/python3.11/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb4202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load(\"word2vec-google-news-300\") #specifying the dataset or type of word embeddings you want to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775efb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e82eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load(\"word2vec-google-news-300\") #specifying the dataset or type of word embeddings you want to download\n",
    "\n",
    "#all available models here:\n",
    "#https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf949483",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfed463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.729151"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1 = \"great\", w2 = \"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96dce28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40982714"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1 = \"great\", w2 = \"well\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2876cc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4778369"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1 = \"well\", w2 = \"good\") #not synonyms but based on context in which they appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23fe227b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34199455"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1 = \"profit\", w2 = \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1830147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.7291508913040161),\n",
       " ('bad', 0.7190051078796387),\n",
       " ('terrific', 0.6889115571975708),\n",
       " ('decent', 0.6837348937988281),\n",
       " ('nice', 0.6836092472076416),\n",
       " ('excellent', 0.644292950630188),\n",
       " ('fantastic', 0.6407778263092041),\n",
       " ('better', 0.6120728850364685),\n",
       " ('solid', 0.5806035399436951),\n",
       " ('lousy', 0.576420247554779)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"good\") #most similar words to good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6ebf3",
   "metadata": {},
   "source": [
    "Word vectors recognize similar words like good and great but BOW and \n",
    "TF-IDF are dumber models and can't recognize that good and great are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc43fc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.7291508913040161),\n",
       " ('bad', 0.7190051078796387),\n",
       " ('terrific', 0.6889115571975708),\n",
       " ('decent', 0.6837348937988281),\n",
       " ('nice', 0.6836092472076416),\n",
       " ('excellent', 0.644292950630188),\n",
       " ('fantastic', 0.6407778263092041),\n",
       " ('better', 0.6120728850364685),\n",
       " ('solid', 0.5806035399436951),\n",
       " ('lousy', 0.576420247554779)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a08bbd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593235015869),\n",
       " ('monarchy', 0.5087411403656006)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#king - man + woman = queen\n",
    "#this kind of math is easy to do with gensim but more inconvenient with spacy\n",
    "\n",
    "wv.most_similar(positive=[\"king\", \"woman\"], negative = [\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ee5dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.5094343423843384),\n",
       " ('european', 0.4865044951438904),\n",
       " ('german', 0.4714890122413635),\n",
       " ('austria', 0.46964019536972046),\n",
       " ('swedish', 0.4645182490348816),\n",
       " ('Wissenschaft', 0.4532880485057831),\n",
       " ('denmark', 0.4477355182170868),\n",
       " ('München', 0.4438531994819641),\n",
       " ('europe', 0.4420619606971741),\n",
       " ('belgium', 0.43769749999046326)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[\"france\", \"berlin\"], negative = [\"paris\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "764388db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doesnt_match = if you give a set of key words, it will return the odd one out\n",
    "wv.doesnt_match([\"facebook\", \"cat\", \"amazon\", \"microsoft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8a74913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alaska'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match([\"munich\", \"germany\", \"berlin\", \"alaska\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01471a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all available models here:\n",
    "#https://github.com/RaRe-Technologies/gensim-data\n",
    "\n",
    "#loading another model from here\n",
    "glv = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f676f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4878e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('too', 0.9648017287254333),\n",
       " ('day', 0.9533665180206299),\n",
       " ('well', 0.9503171443939209),\n",
       " ('nice', 0.9438972473144531),\n",
       " ('better', 0.9425961971282959),\n",
       " ('fun', 0.9418926239013672),\n",
       " ('much', 0.9413353800773621),\n",
       " ('this', 0.9387555122375488),\n",
       " ('hope', 0.9383508563041687),\n",
       " ('great', 0.9378516674041748)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43a0cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.7291508913040161),\n",
       " ('bad', 0.7190051078796387),\n",
       " ('terrific', 0.6889115571975708),\n",
       " ('decent', 0.6837348937988281),\n",
       " ('nice', 0.6836092472076416),\n",
       " ('excellent', 0.644292950630188),\n",
       " ('fantastic', 0.6407778263092041),\n",
       " ('better', 0.6120728850364685),\n",
       " ('solid', 0.5806035399436951),\n",
       " ('lousy', 0.576420247554779)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d539af55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('qualcomm', 0.9118991494178772),\n",
       " ('motors', 0.9075974822044373),\n",
       " ('sachs', 0.8855622410774231),\n",
       " ('alibaba', 0.8841804265975952),\n",
       " ('weber', 0.8666931390762329),\n",
       " ('deere', 0.8601743578910828),\n",
       " ('kernel', 0.8578172922134399),\n",
       " ('foxconn', 0.8552562594413757),\n",
       " ('citigroup', 0.8552471399307251),\n",
       " ('exxon', 0.8550337553024292)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.most_similar(\"tesla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c838e9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nikola', 0.8904832601547241),\n",
       " ('hartmann', 0.879829466342926),\n",
       " ('strunk', 0.879176139831543),\n",
       " ('ice-t', 0.8784680366516113),\n",
       " ('hefner', 0.8749244213104248),\n",
       " ('safdar', 0.8681180477142334),\n",
       " ('o’hara', 0.8664085268974304),\n",
       " ('dejesus', 0.861048698425293),\n",
       " ('corning', 0.8586575984954834),\n",
       " ('laverne', 0.8582468628883362)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.most_similar(\"musk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8af3fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dhoni', 0.9746218919754028),\n",
       " ('virat', 0.9556356072425842),\n",
       " ('afridi', 0.9315229058265686),\n",
       " ('jadeja', 0.9268335103988647),\n",
       " ('gayle', 0.9266006350517273),\n",
       " ('ashwin', 0.9253957271575928),\n",
       " ('yuvraj', 0.9214871525764465),\n",
       " ('dravid', 0.9159311652183533),\n",
       " ('toews', 0.9144657254219055),\n",
       " ('rohit', 0.9103794097900391)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.most_similar(\"kohli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa49e4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.doesnt_match([\"breakfast\", \"cereal\", \"dinner\", \"lunch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcae2713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.doesnt_match([\"banana\", \"human\", \"grapes\", \"orange\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d6023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e407fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
